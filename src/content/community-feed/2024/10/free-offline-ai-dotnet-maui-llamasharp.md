---
title: "Free offline AI in .NET MAUI Application"
link: https://vladislavantonyuk.github.io/articles/Free-offline-AI-in-.NET-MAUI-Application/
description: Run LLMs locally in a .NET MAUI app using LLamaSharp, with guidance on model formats, setup, and performance tradeoffs for offline scenarios.
date: 2024-10-30
author: VladislavAntonyuk
---

Offline-first AI is useful when you care about privacy, reliability, or avoiding per-request cloud costs—and it’s increasingly practical on modern devices.

This post walks through using **LLamaSharp** in a .NET MAUI app, including choosing a compatible GGUF model, wiring up inference, and tuning for device performance.
